{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOp1/GeiZApJP8+D1+O8caa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abdul-Haseeb-boonig/CS-417-Lab9/blob/main/ParallelProcessingLab9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install virtualenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jS-jxria9zco",
        "outputId": "eeaf4701-b408-40a0-bf2d-75bfacae067b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting virtualenv\n",
            "  Downloading virtualenv-20.25.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting distlib<1,>=0.3.7 (from virtualenv)\n",
            "  Downloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock<4,>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (3.13.1)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (4.1.0)\n",
            "Installing collected packages: distlib, virtualenv\n",
            "Successfully installed distlib-0.3.8 virtualenv-20.25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lE3LeM57921O",
        "outputId": "7411ca01-8fa6-4e03-ad06-3a1413580d12"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5WRhX8-93Ku",
        "outputId": "be360db6-58d2-466c-bf92-59ee2d40e188"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-xeff5m_r\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-xeff5m_r\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0a71d56e5dce3ff1f0dd2c47c29367629262f527\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4293 sha256=1704fff7a33ec9e696ff9210d5ec4bdb6587a7e0a1a3d16e03749f07f8b81e6b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-r5e81bfh/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwVDjxc093OC",
        "outputId": "e63a0160-7c9f-470f-f3f6-ed75b05c297f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "// Matrix multiplication kernel\n",
        "__global__ void matrixMul(const int *A, const int *B, int *C, int N) {\n",
        "int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "if (row < N && col < N) {\n",
        "int result = 0;\n",
        "for (int k = 0; k < N; ++k) {\n",
        "result += A[row * N + k] * B[k * N + col];\n",
        "}\n",
        "C[row * N + col] = result;\n",
        "}\n",
        "}\n",
        "// Function to print a matrix\n",
        "void printMatrix(const int *matrix, int rows, int cols) {\n",
        "for (int i = 0; i < rows; ++i) {\n",
        "for (int j = 0; j < cols; ++j) {\n",
        "std::cout << matrix[i * cols + j] << \" \";\n",
        "}\n",
        "std::cout << std::endl;\n",
        "}\n",
        "std::cout << std::endl;\n",
        "}\n",
        "int main() {\n",
        "const int N = 3; // Size of the matrices (NxN)\n",
        "// Example matrices A and B\n",
        "const int A[N][N] = {{1, 2, 3}, {4, 5, 6}, {7, 8, 9}};\n",
        "const int B[N][N] = {{9, 8, 7}, {6, 5, 4}, {3, 2, 1}};\n",
        "// Allocate memory for matrices on the host\n",
        "int C_cpu[N][N]; // Result matrix from CPU\n",
        "int C_gpu[N][N]; // Result matrix from GPU\n",
        "// Allocate memory for matrices on the device\n",
        "int *d_A, *d_B, *d_C;\n",
        "cudaMalloc((void **)&d_A, N * N * sizeof(int));\n",
        "cudaMalloc((void **)&d_B, N * N * sizeof(int));\n",
        "cudaMalloc((void **)&d_C, N * N * sizeof(int));\n",
        "// Copy matrices A and B from host to device\n",
        "cudaMemcpy(d_A, &A[0][0], N * N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "cudaMemcpy(d_B, &B[0][0], N * N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "// Define block and grid dimensions\n",
        "dim3 blockDim(2, 2); // 2x2 thread block\n",
        "dim3 gridDim((N + blockDim.x - 1) / blockDim.x, (N + blockDim.y - 1) / blockDim.y);\n",
        "// Launch the matrix multiplication kernel\n",
        "matrixMul<<<gridDim, blockDim>>>(d_A, d_B, d_C, N);\n",
        "// Copy the result matrix from device to host\n",
        "cudaMemcpy(&C_gpu[0][0], d_C, N * N * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "// Matrix multiplication on CPU for comparison\n",
        "for (int i = 0; i < N; ++i) {\n",
        "for (int j = 0; j < N; ++j) {\n",
        "C_cpu[i][j] = 0;\n",
        "for (int k = 0; k < N; ++k) {\n",
        "C_cpu[i][j] += A[i][k] * B[k][j];\n",
        "}\n",
        "}\n",
        "}\n",
        "// Print matrices A, B, and C_cpu (result from CPU)\n",
        "std::cout << \"Matrix A:\" << std::endl;\n",
        "printMatrix(&A[0][0], N, N);\n",
        "std::cout << \"Matrix B:\" << std::endl;\n",
        "printMatrix(&B[0][0], N, N);\n",
        "std::cout << \"Result from CPU (C_cpu):\" << std::endl;\n",
        "printMatrix(&C_cpu[0][0], N, N);\n",
        "// Print the result from the GPU (C_gpu)\n",
        "std::cout << \"Result from GPU (C_gpu):\" << std::endl;\n",
        "printMatrix(&C_gpu[0][0], N, N);\n",
        "// Compare the results\n",
        "bool resultMatch = true;\n",
        "for (int i = 0; i < N; ++i) {\n",
        "for (int j = 0; j < N; ++j) {\n",
        "if (C_cpu[i][j] != C_gpu[i][j]) {\n",
        "resultMatch = false;\n",
        "break;\n",
        "}\n",
        "}\n",
        "}\n",
        "if (resultMatch) {\n",
        "std::cout << \"Results match between CPU and GPU implementations.\" << std::endl;\n",
        "} else {\n",
        "std::cout << \"Results do not match between CPU and GPU implementations.\" << std::endl;\n",
        "}\n",
        "// Free device memory\n",
        "cudaFree(d_A);\n",
        "cudaFree(d_B);\n",
        "cudaFree(d_C);\n",
        "return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrrYajbd7pZP",
        "outputId": "f7129659-bfca-4a4b-e7be-a4e5917ddc48"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix A:\n",
            "1 2 3 \n",
            "4 5 6 \n",
            "7 8 9 \n",
            "\n",
            "Matrix B:\n",
            "9 8 7 \n",
            "6 5 4 \n",
            "3 2 1 \n",
            "\n",
            "Result from CPU (C_cpu):\n",
            "30 24 18 \n",
            "84 69 54 \n",
            "138 114 90 \n",
            "\n",
            "Result from GPU (C_gpu):\n",
            "0 0 0 \n",
            "0 0 0 \n",
            "0 0 0 \n",
            "\n",
            "Results do not match between CPU and GPU implementations.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <iostream>\n",
        "#include <iomanip>\n",
        "#include <cuda_runtime.h>\n",
        "__global__ void matrixMul(const int *A, const int *B, int *C, int N) {\n",
        "    // Define shared memory for tiles of matrices A and B\n",
        "    __shared__ int tileA[2][2];\n",
        "    __shared__ int tileB[2][2];\n",
        "\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    int result = 0;\n",
        "\n",
        "    // Loop over tiles\n",
        "    for (int i = 0; i < N; i += blockDim.x) {\n",
        "        // Load tiles into shared memory\n",
        "        tileA[threadIdx.y][threadIdx.x] = A[row * N + i + threadIdx.x];\n",
        "        tileB[threadIdx.y][threadIdx.x] = B[(i + threadIdx.y) * N + col];\n",
        "\n",
        "        // Synchronize to make sure tiles are loaded before computation\n",
        "        __syncthreads();\n",
        "\n",
        "        // Perform the matrix multiplication using the loaded tiles\n",
        "        for (int k = 0; k < blockDim.x; ++k) {\n",
        "            result += tileA[threadIdx.y][k] * tileB[k][threadIdx.x];\n",
        "        }\n",
        "\n",
        "        // Synchronize before loading the next tile\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Write the result to the output matrix\n",
        "    if (row < N && col < N) {\n",
        "        C[row * N + col] = result;\n",
        "    }\n",
        "}\n",
        "// Function to print a matrix\n",
        "void printMatrix(const int *matrix, int rows, int cols) {\n",
        "for (int i = 0; i < rows; ++i) {\n",
        "for (int j = 0; j < cols; ++j) {\n",
        "std::cout << matrix[i * cols + j] << \" \";\n",
        "}\n",
        "std::cout << std::endl;\n",
        "}\n",
        "std::cout << std::endl;\n",
        "}\n",
        "int main() {\n",
        "const int N = 3; // Size of the matrices (NxN)\n",
        "// Example matrices A and B\n",
        "const int A[N][N] = {{1, 2, 3}, {4, 5, 6}, {7, 8, 9}};\n",
        "const int B[N][N] = {{9, 8, 7}, {6, 5, 4}, {3, 2, 1}};\n",
        "// Allocate memory for matrices on the host\n",
        "int C_cpu[N][N]; // Result matrix from CPU\n",
        "int C_gpu[N][N]; // Result matrix from GPU\n",
        "// Allocate memory for matrices on the device\n",
        "int *d_A, *d_B, *d_C;\n",
        "cudaMalloc((void **)&d_A, N * N * sizeof(int));\n",
        "cudaMalloc((void **)&d_B, N * N * sizeof(int));\n",
        "cudaMalloc((void **)&d_C, N * N * sizeof(int));\n",
        "// Copy matrices A and B from host to device\n",
        "cudaMemcpy(d_A, &A[0][0], N * N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "cudaMemcpy(d_B, &B[0][0], N * N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "// Define block and grid dimensions\n",
        "dim3 blockDim(2, 2); // 2x2 thread block\n",
        "dim3 gridDim((N + blockDim.x - 1) / blockDim.x, (N + blockDim.y - 1) / blockDim.y);\n",
        "clock_t t;\n",
        "t = clock();\n",
        "// Launch the matrix multiplication kernel\n",
        "matrixMul<<<gridDim, blockDim>>>(d_A, d_B, d_C, N);\n",
        "t = clock() - t;\n",
        "double time_taken = ((double)t)/CLOCKS_PER_SEC; // in seconds\n",
        "// Copy the result matrix from device to host\n",
        "cudaMemcpy(&C_gpu[0][0], d_C, N * N * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "// Matrix multiplication on CPU for comparison\n",
        "for (int i = 0; i < N; ++i) {\n",
        "for (int j = 0; j < N; ++j) {\n",
        "C_cpu[i][j] = 0;\n",
        "for (int k = 0; k < N; ++k) {\n",
        "C_cpu[i][j] += A[i][k] * B[k][j];\n",
        "}\n",
        "}\n",
        "}\n",
        "// Print the result from the GPU (C_gpu)\n",
        "std::cout << \"Result from GPU (C_gpu):\" << std::endl;\n",
        "printMatrix(&C_gpu[0][0], N, N);\n",
        "\n",
        "// Compare the results\n",
        "bool resultMatch = true;\n",
        "for (int i = 0; i < N; ++i) {\n",
        "for (int j = 0; j < N; ++j) {\n",
        "if (C_cpu[i][j] != C_gpu[i][j]) {\n",
        "resultMatch = false;\n",
        "break;\n",
        "}\n",
        "}\n",
        "}\n",
        "if (resultMatch) {\n",
        "std::cout << \"Results match between CPU and GPU implementations.\" << std::endl;\n",
        "} else {\n",
        "std::cout << \"Results do not match between CPU and GPU implementations.\" << std::endl;\n",
        "}\n",
        "printf(\"GPU with Global Memory took %f seconds to execute \\n\", time_taken);\n",
        "// Free device memory\n",
        "cudaFree(d_A);\n",
        "cudaFree(d_B);\n",
        "cudaFree(d_C);\n",
        "return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xs2_VXfKFd7d",
        "outputId": "6e343318-36a7-4012-c44e-c33eb2bdbb9f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result from GPU (C_gpu):\n",
            "0 0 0 \n",
            "0 0 0 \n",
            "0 0 0 \n",
            "\n",
            "Results do not match between CPU and GPU implementations.\n",
            "GPU with Global Memory took 0.000006 seconds to execute \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gnQQMxQ2DlA0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}